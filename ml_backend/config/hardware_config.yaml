# Hardware Configuration for ML Validation Engine
# 4x NVIDIA H100 (80GB each) = 320GB total GPU memory
# Instance: a3-highgpu-4g on GCP (us-central1-b)
# OS: Rocky Linux 8 with Nvidia driver 580
# Storage: 500GB Hyperdisk Balanced + 8x375GB Local SSD (3TB total)

gpus:
  total: 4
  model: "H100"
  memory_per_gpu_gb: 80
  total_memory_gb: 320
  
  # Multi-GPU strategy
  strategy: "data_parallel"  # data_parallel, model_parallel, or pipeline_parallel
  
  # GPU allocation per tier (4 GPUs total)
  tier_allocation:
    tier_1_micro:  # 76M parameter models (tiny)
      gpus: [0, 1]  # Use 2 GPUs
      batch_size: 256  # Larger batch for FFT efficiency
      parallel_models: 10  # Train 10 models in parallel
    
    tier_2_mini:  # 454M parameter models (small)
      gpus: [0, 1, 2]  # Use 3 GPUs
      batch_size: 128
      parallel_models: 5
    
    tier_3_medium:  # 983M parameter models (base)
      gpus: [0, 1, 2, 3]  # Use all 4 GPUs
      batch_size: 64
      parallel_models: 3

compute_limits:
  max_validation_cost_usd: 2000
  cost_per_gpu_hour_usd: 7.11  # H100 on GCP ($44.36/hr รท 4 GPUs + overhead)
  max_gpu_hours_per_validation: 280  # ~12 days at $2K budget
  
  # Automatic cost tracking
  enable_cost_tracking: true
  alert_threshold_usd: 1800

# GCP Instance Configuration
instance:
  provider: "GCP"
  type: "a3-highgpu-4g"
  region: "us-central1-b"
  zone: "us-central1-b"
  cpus: 104  # vCPU
  ram_gb: 936
  cost_per_hour_usd: 44.36
  cost_per_month_usd: 32383.85

# Storage Configuration
storage:
  boot_disk:
    type: "Hyperdisk Balanced"
    size_gb: 500
    iops: 6000
    throughput_mbps: 890
    cost_per_month_usd: 85.00  # $40 + $15 IOPS + $30 throughput
  
  local_ssd:
    count: 8
    type: "NVMe"
    size_per_disk_gb: 375
    total_gb: 3000
    cost_per_month_usd: 240.00
    mount_path: "/mnt/localssd"
    use_for:
      - "Training data cache"
      - "Model checkpoints"
      - "Temporary embeddings"
      - "Signature library (HDF5)"

# Operating System
os:
  name: "Rocky Linux"
  version: "8"
  nvidia_driver: "580"
  cuda_version: "12.4"  # Latest for driver 580
  cudnn_version: "9.0"

training_config:
  precision: "bf16"  # BF16 recommended for H100 (better than FP16)
  use_gradient_checkpointing: true
  use_flash_attention: false  # NOT USED - no attention mechanism!
  use_fft_optimization: true  # FFT-based spectral processing
  compile_models: true  # torch.compile for speed
  fft_backend: "cufft"  # CUDA FFT library for H100
  enable_tf32: true  # TensorFloat-32 on H100 for extra speed
  
memory_optimization:
  gradient_accumulation_steps: 2
  max_memory_usage_percent: 90
  enable_cpu_offload: false  # We have enough GPU memory
  clear_cache_between_models: true

distributed_config:
  backend: "nccl"  # NVIDIA's optimized backend
  init_method: "env://"
  world_size: 4  # 4 GPUs
  
performance_targets:
  tier_1_time_minutes: 30    # All 10 micro models
  tier_2_time_minutes: 180   # All 5 mini models (3 hours)
  tier_3_time_minutes: 1440  # All 3 medium models (24 hours)
  total_validation_hours: 30  # Target: 30 hours total
